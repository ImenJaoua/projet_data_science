{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pathlib\n",
    "if pathlib.Path().resolve().name == 'notebooks':\n",
    "    %cd ..\n",
    "%pwd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data import NHLDataDownloader\n",
    "from src.features import load_df_shots, add_goalie_ratio, add_opponent_concedes, add_shooter_ratio, add_team_goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nhl = NHLDataDownloader(2016)\n",
    "test = nhl.load_processed_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Shot_distance', 'Shot_angle', 'Goal', 'Empty_net']\n",
    "df_2016 = load_df_shots(2016)\n",
    "df_2017 = load_df_shots(2017)\n",
    "df_2018 = load_df_shots(2018)\n",
    "df_2019 = load_df_shots(2019)\n",
    "df_2020 = load_df_shots(2020)\n",
    "\n",
    "# df_tot = pd.concat([df_2016, df_2017, df_2018, df_2019]).reset_index(drop=True)\n",
    "df = pd.concat([df_2016, df_2017, df_2018, df_2019, df_2020]).reset_index(drop=True)\n",
    "# df = df_tot[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_shooter_ratio(df)\n",
    "df = add_goalie_ratio(df)\n",
    "df = add_team_goals(df)\n",
    "df = add_opponent_concedes(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Strength', axis=1, inplace=True)\n",
    "df.Shot_angle = df.Shot_angle.abs()\n",
    "df.to_pickle(\"final.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle('final.pkl').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.client import start_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = start_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = df[(df.Year == 2017) & (df.Game_id == 1065)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Gam_id' in df:\n",
    "    print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.log_dataframe_profile(subset_df, name='wpg_v_wsh_2017021065', dataframe_format='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_df = df_all[['Year','Game_id','Shooter', 'Goal']]\n",
    "goal_ratio_df = goal_df.groupby(['Year','Game_id', 'Shooter']).Goal.mean().reset_index(name='Goal_ratio')\n",
    "\n",
    "base = pd.DataFrame([[0,0,n,0.1] for n in goal_ratio_df.Shooter.unique()], columns=goal_ratio_df.columns)\n",
    "goal_ratio_df = pd.concat([base, goal_ratio_df]).reset_index(drop=True)\n",
    "goal_ratio_df['Ema'] = goal_ratio_df.groupby('Shooter')['Goal_ratio'].transform(\n",
    "    lambda x: x.ewm(alpha=0.01, adjust=False).mean()\n",
    ")\n",
    "\n",
    "df_all = df_all.drop('Shooter_ratio', axis=1, errors='ignore')\n",
    "\n",
    "goal_ratio_df['Shooter_ratio'] = goal_ratio_df.groupby('Shooter')['Ema'].shift().round(4)\n",
    "df_all = df_all.merge(goal_ratio_df[['Year','Game_id', 'Shooter', 'Shooter_ratio']], how='left', on=['Year','Game_id', 'Shooter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df = df_all[['Year','Game_id','Goalie', 'Goal']]\n",
    "save_ratio_df = save_df.groupby(['Year','Game_id', 'Goalie']).Goal.mean().reset_index(name='Save_ratio')\n",
    "save_ratio_df.Save_ratio = 1 - save_ratio_df.Save_ratio\n",
    "\n",
    "base = pd.DataFrame([[0,0,n,0.9] for n in save_ratio_df.Goalie.unique()], columns=save_ratio_df.columns)\n",
    "save_ratio_df = pd.concat([base, save_ratio_df]).reset_index(drop=True)\n",
    "save_ratio_df['Ema'] = save_ratio_df.groupby('Goalie')['Save_ratio'].transform(\n",
    "    lambda x: x.ewm(alpha=0.01, adjust=False).mean()\n",
    ")\n",
    "\n",
    "df_all = df_all.drop('Goalie_ratio', axis=1, errors='ignore')\n",
    "\n",
    "save_ratio_df['Goalie_ratio'] = save_ratio_df.groupby('Goalie')['Ema'].shift().round(4)\n",
    "df_all = df_all.merge(save_ratio_df[['Year','Game_id', 'Goalie', 'Goalie_ratio']], how='left', on=['Year','Game_id', 'Goalie'])\n",
    "df_all.loc[df_all.Goalie == '', 'Goalie_ratio'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_df = df_all[['Year','Game_id','Team', 'Goal']]\n",
    "goal_ratio_df = goal_df.groupby(['Year','Game_id', 'Team']).apply(\n",
    "    lambda x: x['Goal'].sum()\n",
    ").reset_index(name='Goal_ratio')\n",
    "\n",
    "base = pd.DataFrame([[0,0,n,3] for n in goal_ratio_df.Team.unique()], columns=goal_ratio_df.columns)\n",
    "goal_ratio_df = pd.concat([base, goal_ratio_df]).reset_index(drop=True)\n",
    "goal_ratio_df['Ema'] = goal_ratio_df.groupby('Team')['Goal_ratio'].transform(\n",
    "    lambda x: x.ewm(alpha=0.01, adjust=False).mean()\n",
    ")\n",
    "\n",
    "df_all = df_all.drop('Team_goals', axis=1, errors='ignore')\n",
    "\n",
    "goal_ratio_df['Team_goals'] = goal_ratio_df.groupby('Team')['Ema'].shift().round(4)\n",
    "df_all = df_all.merge(goal_ratio_df[['Year','Game_id', 'Team', 'Team_goals']], how='left', on=['Year','Game_id', 'Team'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_df = df_all[['Year','Game_id', 'OppTeam', 'Goal']]\n",
    "goal_ratio_df = goal_df.groupby(['Year','Game_id', 'OppTeam']).apply(\n",
    "    lambda x: x['Goal'].sum()\n",
    ").reset_index(name='Goals')\n",
    "\n",
    "base = pd.DataFrame([[0,0,n,3] for n in goal_ratio_df.OppTeam.unique()], columns=goal_ratio_df.columns)\n",
    "goal_ratio_df = pd.concat([base, goal_ratio_df]).reset_index(drop=True)\n",
    "goal_ratio_df['Ema'] = goal_ratio_df.groupby('OppTeam')['Goals'].transform(\n",
    "    lambda x: x.ewm(alpha=0.01, adjust=False).mean()\n",
    ")\n",
    "\n",
    "df_all = df_all.drop('Opp_concedes', axis=1, errors='ignore')\n",
    "\n",
    "goal_ratio_df['Opp_concedes'] = goal_ratio_df.groupby('OppTeam')['Ema'].shift().round(4)\n",
    "df_all = df_all.merge(goal_ratio_df[['Year','Game_id', 'OppTeam', 'Opp_concedes']], how='left', on=['Year','Game_id', 'OppTeam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "\n",
    "ddd = pd.DataFrame([[\"1 / 500 / 4 \", 0.777], [\"1.5 / 400 / 4 \", 0.781], [\"2 / 200 / 5 \", 0.78], [\"3 / 300 / 6 \", 0.776]],\n",
    "                   columns=['hypers', 'AUC'])\n",
    "\n",
    "\n",
    "# ddd\n",
    "fig = px.histogram(ddd, x='AUC', y='hypers', labels=dict(hypers=\"Pos Weight / Estimators / Max depth\"), histfunc='avg')\n",
    "\n",
    "# px.scatter_3d(x=[3,1,1.5], y=[300,500,400], z=[0.777,0.776,0.781], color=[1,2,3],\n",
    "#               labels=dict(x=\"Pos Weight\", y=\"Estimators\", z=\"AUC\", color='accuracy'))\n",
    "\n",
    "# import plotly.express as px\n",
    "# fig = px.scatter_3d(x=[3,1,1.5], y=[300,500,400], z=[0.777,0.776,0.781], color=[1,2,3])\n",
    "fig.update_xaxes(range=[0.76, 0.79])\n",
    "fig.show()\n",
    "fig.write_html(f'../NHL-blog/_includes/hp-tuning.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = df[[\n",
    "        'Game_id',\n",
    "        'Game_time',\n",
    "        'Type',\n",
    "        # 'Empty_net',\n",
    "        'Previous_distance',\n",
    "        # 'X_diff',\n",
    "        'Speed',\n",
    "        # 'Period',\n",
    "        # 'Is_rebound',\n",
    "        'Time_since_powp',\n",
    "        'Players',\n",
    "        'Opp_players',\n",
    "        'P_diff',\n",
    "        'Shot_distance',\n",
    "        # 'X_net',\n",
    "        'Shot_angle',\n",
    "        'Rebound_angle',\n",
    "        'Year',\n",
    "        'Shooter_ratio',\n",
    "        'Goalie_ratio',\n",
    "        'Team_goals',\n",
    "        'Opp_concedes',\n",
    "        'Previous_event_type',\n",
    "        'Goal']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2016 = load_df_shots(2016)\n",
    "df_2017 = load_df_shots(2017)\n",
    "df_2018 = load_df_shots(2018)\n",
    "df_2019 = load_df_shots(2019)\n",
    "df_2020 = load_df_shots(2020)\n",
    "\n",
    "df = pd.concat([df_2016, df_2017, df_2018, df_2019, df_2020]).reset_index(drop=True)\n",
    "\n",
    "df = add_shooter_ratio(df)\n",
    "df = add_goalie_ratio(df)\n",
    "df = add_team_goals(df)\n",
    "df = add_opponent_concedes(df)\n",
    "\n",
    "df.Shot_angle = df.Shot_angle.abs()\n",
    "df['Powp'] = df.Players - df.Opp_players\n",
    "df.loc[df.Powp < 0, 'Powp'] = 0\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot.loc[df_tot.P_diff < 0, 'P_diff'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, normalize, minmax_scale\n",
    "enc = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot.Game_time = minmax_scale(df_tot.Game_time.values)\n",
    "\n",
    "df_tot.Previous_distance = minmax_scale(df_tot.Previous_distance.values)\n",
    "df_tot.Speed = minmax_scale(df_tot.Speed.values)\n",
    "df_tot.Time_since_powp = minmax_scale(df_tot.Time_since_powp.values)\n",
    "df_tot.Shot_distance = minmax_scale(df_tot.Shot_distance.values)\n",
    "\n",
    "df_tot.Shooter_ratio = minmax_scale(df_tot.Shooter_ratio.values)\n",
    "df_tot.Goalie_ratio = minmax_scale(df_tot.Goalie_ratio.values)\n",
    "df_tot.Team_goals = minmax_scale(df_tot.Team_goals.values)\n",
    "df_tot.Opp_concedes = minmax_scale(df_tot.Opp_concedes.values)\n",
    "# df_tot.Players = minmax_scale(df_tot.Players.values)\n",
    "# df_tot.Opp_players = minmax_scale(df_tot.Opp_players.values)\n",
    "df_tot.P_diff = minmax_scale(df_tot.P_diff.values)\n",
    "\n",
    "df_tot.Shot_angle = df_tot.Shot_angle.abs()\n",
    "df_tot.Shot_angle = minmax_scale(df_tot.Shot_angle.values)\n",
    "df_tot.Rebound_angle = minmax_scale(df_tot.Rebound_angle.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "\n",
    "df_train = df_tot[df_tot.Year < 2020].drop('Year', axis=1)\n",
    "df_val = df_tot[df_tot.Year == 2020].drop('Year', axis=1)\n",
    "df_test = df_tot[df_tot.Year == 2020].drop('Year', axis=1)\n",
    "\n",
    "if 'Type' in df_tot:\n",
    "    type_enc = df_train.groupby('Type').Goal.mean().reset_index(name='Type_enc')\n",
    "    df_train = df_train.drop('Type_enc', axis=1, errors='ignore')\n",
    "    df_train = df_train.merge(type_enc[['Type', 'Type_enc']], how='left', on=['Type'])\n",
    "    df_train = df_train.drop('Type', axis=1, errors='ignore')\n",
    "    df_val = df_val.drop('Type_enc', axis=1, errors='ignore')\n",
    "    df_val = df_val.merge(type_enc[['Type', 'Type_enc']], how='left', on=['Type'])\n",
    "    df_val = df_val.drop('Type', axis=1, errors='ignore')\n",
    "    df_test = df_test.drop('Type_enc', axis=1, errors='ignore')\n",
    "    df_test = df_test.merge(type_enc[['Type', 'Type_enc']], how='left', on=['Type'])\n",
    "    df_test = df_test.drop('Type', axis=1, errors='ignore')\n",
    "\n",
    "    # df_train.Type_enc = minmax_scale(df_train.Type_enc.values)\n",
    "    # df_val.Type_enc = minmax_scale(df_val.Type_enc.values)\n",
    "    # df_test.Type_enc = minmax_scale(df_test.Type_enc.values)\n",
    "    # df_train.Type = enc.fit_transform(df_train.Type.values.reshape(-1,1)).reshape(-1)\n",
    "    # df_val.Type = enc.fit_transform(df_val.Type.values.reshape(-1,1)).reshape(-1)\n",
    "    # df_test.Type = enc.transform(df_test.Type.values.reshape(-1,1)).reshape(-1)\n",
    "\n",
    "# df_train.Empty_net = df_train.Empty_net.astype(int)\n",
    "# df_train.Is_rebound = df_train.Is_rebound.astype(int)\n",
    "df_train.Goal = df_train.Goal.astype(float)\n",
    "\n",
    "# df_val.Empty_net = df_val.Empty_net.astype(int)\n",
    "# df_val.Is_rebound = df_val.Is_rebound.astype(int)\n",
    "df_val.Goal = df_val.Goal.astype(float)\n",
    "\n",
    "# df_test.Empty_net = df_test.Empty_net.astype(int)\n",
    "# df_test.Is_rebound = df_test.Is_rebound.astype(int)\n",
    "df_test.Goal = df_test.Goal.astype(float)\n",
    "\n",
    "train_labels = df_train.Goal.values.reshape(-1,1)\n",
    "val_labels = df_val.Goal.values.reshape(-1,1)\n",
    "test_labels = df_test.Goal.values.reshape(-1,1)\n",
    "\n",
    "pos = df_train.Goal.sum()\n",
    "neg = len(df_train) - df_train.Goal.sum()\n",
    "tot = len(df_train)\n",
    "class_weight = {0: (1 / neg) * (tot/2.0), 1: (1 / pos) * (tot/2.0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_enc = df_train.groupby('Previous_event_type').Goal.mean().reset_index(name='Pe_enc')\n",
    "df_train = df_train.drop('Pe_enc', axis=1, errors='ignore')\n",
    "df_train = df_train.merge(type_enc[['Previous_event_type', 'Pe_enc']], how='left', on=['Previous_event_type'])\n",
    "df_train = df_train.drop('Previous_event_type', axis=1, errors='ignore')\n",
    "\n",
    "df_val = df_val.drop('Pe_enc', axis=1, errors='ignore')\n",
    "df_val = df_val.merge(type_enc[['Previous_event_type', 'Pe_enc']], how='left', on=['Previous_event_type'])\n",
    "df_val = df_val.drop('Previous_event_type', axis=1, errors='ignore')\n",
    "df_val.Pe_enc.fillna(df_val.Pe_enc.mean(), inplace=True)\n",
    "\n",
    "df_test = df_test.drop('Pe_enc', axis=1, errors='ignore')\n",
    "df_test = df_test.merge(type_enc[['Previous_event_type', 'Pe_enc']], how='left', on=['Previous_event_type'])\n",
    "df_test = df_test.drop('Previous_event_type', axis=1, errors='ignore')\n",
    "df_test.Pe_enc.fillna(df_test.Pe_enc.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "\n",
    "X_train = df_train.Shot_distance\n",
    "y_train = df_train.Goal\n",
    "X_test = df_test.Shot_distance\n",
    "y_test = df_test.Goal\n",
    "\n",
    "bst = XGBClassifier()\n",
    "bst.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "\n",
    "X_train = df_train.drop('Goal', axis=1)\n",
    "y_train = df_train.Goal\n",
    "X_test = df_test.drop('Goal', axis=1)\n",
    "y_test = df_test.Goal\n",
    "\n",
    "bst = XGBClassifier(scale_pos_weight=9)\n",
    "# fit model\n",
    "bst.fit(X_train, y_train)\n",
    "# make predictions\n",
    "preds = bst.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_decision_forests as tfdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_train, label=\"Goal\")\n",
    "val_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_val, label=\"Goal\")\n",
    "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(df_test, label=\"Goal\")\n",
    "\n",
    "model = tfdf.keras.RandomForestModel(num_trees=550, max_depth=30)\n",
    "# model.fit(train_ds)\n",
    "model.fit(train_ds, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "43597 / df_val[df_val.Goal == 0].Goal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4487 / df_val[df_val.Goal == 1].Goal.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrcs = [metrics.AUC(), metrics.AUC(curve='PR', name='auc_pr'), metrics.Precision(), metrics.Recall()]\n",
    "model.compile(metrics=mtrcs)\n",
    "eval = model.evaluate(val_ds)[1:]\n",
    "mtrs_dir = {mtr.name:eval[i] for i, mtr in enumerate(mtrcs)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtrs_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "model.compile(metrics=['accuracy', metrics.AUC(), metrics.AUC(curve='PR'), metrics.Precision(), metrics.Recall()])\n",
    "model.evaluate(val_ds)\n",
    "# predictions = model.predict(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "model.compile(metrics.AUC(), 'accuracy')\n",
    "model.evaluate(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val = df_val.Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def plots(y_valid, y_prob, model_name):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.6)\n",
    "    plt.suptitle(f'Performance Evaluation of: {model_name}', fontsize=16)\n",
    "\n",
    "\n",
    "    # Plot ROC curve and calculate AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_valid, y_prob)\n",
    "    roc_auc = roc_auc_score(y_valid, y_prob)\n",
    "\n",
    "    axes[0,0].plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    axes[0,0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[0,0].set_xlim([0.0, 1.0])\n",
    "    axes[0,0].set_ylim([0.0, 1.05])\n",
    "    axes[0,0].set_xlabel('False Positive Rate')\n",
    "    axes[0,0].set_ylabel('True Positive Rate')\n",
    "    axes[0,0].set_title('Receiver Operating Characteristic (ROC)')\n",
    "    axes[0,0].legend(loc=\"lower right\")\n",
    "\n",
    "    \n",
    "\n",
    "    axes[0,1].plot([0, 1], [0, 1], 'k:', label=\"Perfectly calibrated\")\n",
    "    prob_true, prob_pred = calibration_curve(y_valid, y_prob, n_bins=10)\n",
    "    axes[0,1].plot(prob_pred, prob_true, 's-', label=\"%s\" % ('clf_distance',))\n",
    "    axes[0,1].set_ylabel('Fraction of positives')\n",
    "    axes[0,1].set_xlabel('Mean predicted probability')\n",
    "    axes[0,1].set_title('Calibration Plot')\n",
    "\n",
    "    # Calculate and plot the rate of goals and cumulative proportion of goals\n",
    "    sorted_indices = np.argsort(y_prob)\n",
    "    sorted_goals = y_valid[sorted_indices]\n",
    "    predicted_probs = y_prob[sorted_indices]\n",
    "\n",
    "    n_bins = 20\n",
    "    bins = np.linspace(0, 1, n_bins + 1)\n",
    "    midpoints = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    goal_rates = []\n",
    "    for i in range(n_bins):\n",
    "        start_idx = int(i * len(predicted_probs) / n_bins)\n",
    "        end_idx = int((i + 1) * len(predicted_probs) / n_bins)\n",
    "        \n",
    "        goals = sum(sorted_goals[start_idx:end_idx])\n",
    "        total_shots = end_idx - start_idx\n",
    "        \n",
    "        goal_rate = 100 * goals / total_shots\n",
    "        goal_rates.append(goal_rate)\n",
    "\n",
    "    axes[1,0].plot(midpoints*100, goal_rates, linestyle='-')\n",
    "    axes[1,0].set_xlim([100,0])\n",
    "    axes[1,0].set_ylim([0,100])\n",
    "    axes[1,0].set_xlabel('Centile of Probability')\n",
    "    axes[1,0].set_ylabel('Rate of Goals')\n",
    "    axes[1,0].set_title('Rate of Goals vs. Centile of Probability')\n",
    "\n",
    "    cumulative_goals = np.cumsum(sorted_goals[::-1])\n",
    "    tot_goals = y_valid.sum()\n",
    "\n",
    "    axes[1,1].plot(np.arange(len(y_prob), 0, -1) * 100 / len(y_prob), cumulative_goals * 100 / tot_goals, linestyle='-')\n",
    "    axes[1,1].set_xlim([100,0])\n",
    "    axes[1,1].set_ylim([0,100])\n",
    "    axes[1,1].set_xlabel('Centile of Probability')\n",
    "    axes[1,1].set_ylabel('Cumulative Proportion of Goals')\n",
    "    axes[1,1].set_title('Cumulative Proportion of Goals vs. Centile of Probability')\n",
    "\n",
    "    # Display the figure with two subplots side by side\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots(y_val, predictions.reshape(-1), \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, _ = roc_curve(val_labels, predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(val_labels, predictions)\n",
    "auc_score = auc(recall, precision)\n",
    "\n",
    "# Plotting ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(recall, precision, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
